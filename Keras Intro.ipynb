{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid, X_train = X_train_full[:5000] / 255.0, X_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Tshirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_valid[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Sequential API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")], name=\"Mnist_Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Mnist_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x15e51b39040>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x15e51b52e20>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x15e68267160>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x15e682674c0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.core.Dense at 0x15e68267160>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer(\"dense_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = model.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05000402, -0.05992961,  0.05164048, ..., -0.05234205,\n",
       "        -0.01248426, -0.03273728],\n",
       "       [ 0.0473929 , -0.02704047, -0.04920133, ..., -0.04943941,\n",
       "         0.03178407, -0.00458083],\n",
       "       [ 0.05693263,  0.06473388, -0.06849327, ...,  0.06955715,\n",
       "         0.04206069,  0.04217813],\n",
       "       ...,\n",
       "       [ 0.01247553,  0.01175727, -0.03685341, ..., -0.00403559,\n",
       "        -0.05103397, -0.06850313],\n",
       "       [ 0.03135417,  0.00833406, -0.02345856, ..., -0.04291496,\n",
       "        -0.06594567,  0.00158928],\n",
       "       [ 0.06198055,  0.04352616,  0.0503033 , ...,  0.04565582,\n",
       "        -0.02950408,  0.07359961]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "             optimizer=\"sgd\",\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2239 - accuracy: 0.9191 - val_loss: 0.3120 - val_accuracy: 0.8840\n",
      "Epoch 2/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2204 - accuracy: 0.9205 - val_loss: 0.3011 - val_accuracy: 0.8906\n",
      "Epoch 3/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2172 - accuracy: 0.9218 - val_loss: 0.2926 - val_accuracy: 0.8932\n",
      "Epoch 4/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2128 - accuracy: 0.9231 - val_loss: 0.3041 - val_accuracy: 0.8888\n",
      "Epoch 5/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2104 - accuracy: 0.9246 - val_loss: 0.2869 - val_accuracy: 0.8968\n",
      "Epoch 6/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2059 - accuracy: 0.9265 - val_loss: 0.2985 - val_accuracy: 0.8910\n",
      "Epoch 7/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2044 - accuracy: 0.9264 - val_loss: 0.3037 - val_accuracy: 0.8878\n",
      "Epoch 8/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.2001 - accuracy: 0.9279 - val_loss: 0.2937 - val_accuracy: 0.8926\n",
      "Epoch 9/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1978 - accuracy: 0.9303 - val_loss: 0.2893 - val_accuracy: 0.8962\n",
      "Epoch 10/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1943 - accuracy: 0.9308 - val_loss: 0.2926 - val_accuracy: 0.8912\n",
      "Epoch 11/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1915 - accuracy: 0.9317 - val_loss: 0.2979 - val_accuracy: 0.8950\n",
      "Epoch 12/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1894 - accuracy: 0.9316 - val_loss: 0.2876 - val_accuracy: 0.8978\n",
      "Epoch 13/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1854 - accuracy: 0.9339 - val_loss: 0.3010 - val_accuracy: 0.8932\n",
      "Epoch 14/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1840 - accuracy: 0.9334 - val_loss: 0.3064 - val_accuracy: 0.8918\n",
      "Epoch 15/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1792 - accuracy: 0.9367 - val_loss: 0.2950 - val_accuracy: 0.8958\n",
      "Epoch 16/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1775 - accuracy: 0.9369 - val_loss: 0.2900 - val_accuracy: 0.8958\n",
      "Epoch 17/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1747 - accuracy: 0.9373 - val_loss: 0.3132 - val_accuracy: 0.8876\n",
      "Epoch 18/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1713 - accuracy: 0.9388 - val_loss: 0.2990 - val_accuracy: 0.8950\n",
      "Epoch 19/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1679 - accuracy: 0.9413 - val_loss: 0.3039 - val_accuracy: 0.8922\n",
      "Epoch 20/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1659 - accuracy: 0.9416 - val_loss: 0.2920 - val_accuracy: 0.8994\n",
      "Epoch 21/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1639 - accuracy: 0.9417 - val_loss: 0.3021 - val_accuracy: 0.8936\n",
      "Epoch 22/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1607 - accuracy: 0.9434 - val_loss: 0.2882 - val_accuracy: 0.8966\n",
      "Epoch 23/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1585 - accuracy: 0.9437 - val_loss: 0.3213 - val_accuracy: 0.8928\n",
      "Epoch 24/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1557 - accuracy: 0.9449 - val_loss: 0.2902 - val_accuracy: 0.8994\n",
      "Epoch 25/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1536 - accuracy: 0.9456 - val_loss: 0.3056 - val_accuracy: 0.8948\n",
      "Epoch 26/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1513 - accuracy: 0.9462 - val_loss: 0.3248 - val_accuracy: 0.8950\n",
      "Epoch 27/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1498 - accuracy: 0.9474 - val_loss: 0.3154 - val_accuracy: 0.8860\n",
      "Epoch 28/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1471 - accuracy: 0.9479 - val_loss: 0.3061 - val_accuracy: 0.8928\n",
      "Epoch 29/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1440 - accuracy: 0.9491 - val_loss: 0.2971 - val_accuracy: 0.8978\n",
      "Epoch 30/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1419 - accuracy: 0.9508 - val_loss: 0.3031 - val_accuracy: 0.8954\n",
      "Epoch 31/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1392 - accuracy: 0.9514 - val_loss: 0.2984 - val_accuracy: 0.8958\n",
      "Epoch 32/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1372 - accuracy: 0.9519 - val_loss: 0.3000 - val_accuracy: 0.8984\n",
      "Epoch 33/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1357 - accuracy: 0.9523 - val_loss: 0.3206 - val_accuracy: 0.8948\n",
      "Epoch 34/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1324 - accuracy: 0.9540 - val_loss: 0.3152 - val_accuracy: 0.8910\n",
      "Epoch 35/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1307 - accuracy: 0.9541 - val_loss: 0.3003 - val_accuracy: 0.8974\n",
      "Epoch 36/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1286 - accuracy: 0.9552 - val_loss: 0.3373 - val_accuracy: 0.8834\n",
      "Epoch 37/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1279 - accuracy: 0.9552 - val_loss: 0.3092 - val_accuracy: 0.8946\n",
      "Epoch 38/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1236 - accuracy: 0.9570 - val_loss: 0.3197 - val_accuracy: 0.8958\n",
      "Epoch 39/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1239 - accuracy: 0.9575 - val_loss: 0.3502 - val_accuracy: 0.8892\n",
      "Epoch 40/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1202 - accuracy: 0.9582 - val_loss: 0.3213 - val_accuracy: 0.8940\n",
      "Epoch 41/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1185 - accuracy: 0.9590 - val_loss: 0.3173 - val_accuracy: 0.8968\n",
      "Epoch 42/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1169 - accuracy: 0.9591 - val_loss: 0.3334 - val_accuracy: 0.8948\n",
      "Epoch 43/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1151 - accuracy: 0.9604 - val_loss: 0.3201 - val_accuracy: 0.8948\n",
      "Epoch 44/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1136 - accuracy: 0.9604 - val_loss: 0.3421 - val_accuracy: 0.8920\n",
      "Epoch 45/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1110 - accuracy: 0.9620 - val_loss: 0.3158 - val_accuracy: 0.9000\n",
      "Epoch 46/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1105 - accuracy: 0.9622 - val_loss: 0.3095 - val_accuracy: 0.8974\n",
      "Epoch 47/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1061 - accuracy: 0.9633 - val_loss: 0.3261 - val_accuracy: 0.8942\n",
      "Epoch 48/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1062 - accuracy: 0.9635 - val_loss: 0.3404 - val_accuracy: 0.8932\n",
      "Epoch 49/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1045 - accuracy: 0.9641 - val_loss: 0.3185 - val_accuracy: 0.8934\n",
      "Epoch 50/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1019 - accuracy: 0.9644 - val_loss: 0.3317 - val_accuracy: 0.8944\n",
      "Epoch 51/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.1017 - accuracy: 0.9646 - val_loss: 0.3278 - val_accuracy: 0.8956\n",
      "Epoch 52/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0977 - accuracy: 0.9665 - val_loss: 0.3441 - val_accuracy: 0.8878\n",
      "Epoch 53/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0973 - accuracy: 0.9674 - val_loss: 0.3274 - val_accuracy: 0.8938\n",
      "Epoch 54/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0969 - accuracy: 0.9671 - val_loss: 0.3357 - val_accuracy: 0.8926\n",
      "Epoch 55/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0935 - accuracy: 0.9682 - val_loss: 0.3922 - val_accuracy: 0.8888\n",
      "Epoch 56/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0938 - accuracy: 0.9682 - val_loss: 0.3368 - val_accuracy: 0.8910\n",
      "Epoch 57/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0901 - accuracy: 0.9694 - val_loss: 0.3377 - val_accuracy: 0.8928\n",
      "Epoch 58/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0890 - accuracy: 0.9702 - val_loss: 0.3979 - val_accuracy: 0.8812\n",
      "Epoch 59/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0869 - accuracy: 0.9701 - val_loss: 0.3427 - val_accuracy: 0.8968\n",
      "Epoch 60/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0861 - accuracy: 0.9707 - val_loss: 0.3953 - val_accuracy: 0.8908\n",
      "Epoch 61/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0848 - accuracy: 0.9715 - val_loss: 0.3549 - val_accuracy: 0.8888\n",
      "Epoch 62/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0841 - accuracy: 0.9712 - val_loss: 0.3557 - val_accuracy: 0.8928\n",
      "Epoch 63/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0804 - accuracy: 0.9734 - val_loss: 0.3558 - val_accuracy: 0.8970\n",
      "Epoch 64/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0798 - accuracy: 0.9739 - val_loss: 0.3759 - val_accuracy: 0.8910\n",
      "Epoch 65/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0784 - accuracy: 0.9744 - val_loss: 0.3537 - val_accuracy: 0.8950\n",
      "Epoch 66/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0774 - accuracy: 0.9739 - val_loss: 0.3585 - val_accuracy: 0.8962\n",
      "Epoch 67/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0759 - accuracy: 0.9743 - val_loss: 0.3475 - val_accuracy: 0.8972\n",
      "Epoch 68/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0757 - accuracy: 0.9747 - val_loss: 0.3413 - val_accuracy: 0.8954\n",
      "Epoch 69/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0733 - accuracy: 0.9761 - val_loss: 0.3572 - val_accuracy: 0.8968\n",
      "Epoch 70/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0722 - accuracy: 0.9761 - val_loss: 0.3657 - val_accuracy: 0.8934\n",
      "Epoch 71/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0710 - accuracy: 0.9764 - val_loss: 0.3731 - val_accuracy: 0.8934\n",
      "Epoch 72/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0706 - accuracy: 0.9767 - val_loss: 0.3665 - val_accuracy: 0.8976\n",
      "Epoch 73/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0683 - accuracy: 0.9777 - val_loss: 0.3709 - val_accuracy: 0.8952\n",
      "Epoch 74/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0661 - accuracy: 0.9784 - val_loss: 0.3802 - val_accuracy: 0.8960\n",
      "Epoch 75/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0661 - accuracy: 0.9789 - val_loss: 0.3908 - val_accuracy: 0.8896\n",
      "Epoch 76/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0650 - accuracy: 0.9787 - val_loss: 0.3703 - val_accuracy: 0.8986\n",
      "Epoch 77/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0642 - accuracy: 0.9792 - val_loss: 0.3787 - val_accuracy: 0.8916\n",
      "Epoch 78/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0634 - accuracy: 0.9795 - val_loss: 0.3687 - val_accuracy: 0.8952\n",
      "Epoch 79/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0618 - accuracy: 0.9804 - val_loss: 0.3737 - val_accuracy: 0.8952\n",
      "Epoch 80/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0594 - accuracy: 0.9804 - val_loss: 0.4158 - val_accuracy: 0.8878\n",
      "Epoch 81/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0586 - accuracy: 0.9808 - val_loss: 0.4043 - val_accuracy: 0.8942\n",
      "Epoch 82/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0582 - accuracy: 0.9807 - val_loss: 0.4100 - val_accuracy: 0.8890\n",
      "Epoch 83/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0572 - accuracy: 0.9813 - val_loss: 0.3837 - val_accuracy: 0.8968\n",
      "Epoch 84/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0566 - accuracy: 0.9821 - val_loss: 0.4173 - val_accuracy: 0.8900\n",
      "Epoch 85/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0545 - accuracy: 0.9823 - val_loss: 0.3874 - val_accuracy: 0.8972\n",
      "Epoch 86/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0531 - accuracy: 0.9831 - val_loss: 0.3910 - val_accuracy: 0.8926\n",
      "Epoch 87/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0529 - accuracy: 0.9830 - val_loss: 0.4183 - val_accuracy: 0.8942\n",
      "Epoch 88/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0523 - accuracy: 0.9829 - val_loss: 0.3931 - val_accuracy: 0.8960\n",
      "Epoch 89/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0500 - accuracy: 0.9845 - val_loss: 0.3999 - val_accuracy: 0.8960\n",
      "Epoch 90/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0504 - accuracy: 0.9836 - val_loss: 0.3918 - val_accuracy: 0.8998\n",
      "Epoch 91/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0488 - accuracy: 0.9845 - val_loss: 0.4123 - val_accuracy: 0.8954\n",
      "Epoch 92/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0484 - accuracy: 0.9840 - val_loss: 0.3973 - val_accuracy: 0.8968\n",
      "Epoch 93/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0474 - accuracy: 0.9854 - val_loss: 0.4722 - val_accuracy: 0.8828\n",
      "Epoch 94/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0481 - accuracy: 0.9844 - val_loss: 0.4096 - val_accuracy: 0.8918\n",
      "Epoch 95/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0461 - accuracy: 0.9850 - val_loss: 0.4245 - val_accuracy: 0.8960\n",
      "Epoch 96/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0438 - accuracy: 0.9861 - val_loss: 0.4155 - val_accuracy: 0.8964\n",
      "Epoch 97/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.4258 - val_accuracy: 0.8940\n",
      "Epoch 98/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0424 - accuracy: 0.9873 - val_loss: 0.4327 - val_accuracy: 0.8928\n",
      "Epoch 99/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0421 - accuracy: 0.9869 - val_loss: 0.4361 - val_accuracy: 0.8948\n",
      "Epoch 100/100\n",
      "1719/1719 [==============================] - 3s 2ms/step - loss: 0.0402 - accuracy: 0.9882 - val_loss: 0.4247 - val_accuracy: 0.8968\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.7265991568565369,\n",
       "  0.4927557110786438,\n",
       "  0.4450525939464569,\n",
       "  0.41711336374282837,\n",
       "  0.3959476947784424,\n",
       "  0.37959128618240356,\n",
       "  0.36572006344795227,\n",
       "  0.3530329465866089,\n",
       "  0.3423042893409729,\n",
       "  0.3338049352169037,\n",
       "  0.3245781362056732,\n",
       "  0.3186051547527313,\n",
       "  0.309889018535614,\n",
       "  0.3032786548137665,\n",
       "  0.29709121584892273,\n",
       "  0.29117119312286377,\n",
       "  0.28443655371665955,\n",
       "  0.27978217601776123,\n",
       "  0.27441316843032837,\n",
       "  0.2695232331752777,\n",
       "  0.26348528265953064,\n",
       "  0.2598818242549896,\n",
       "  0.2552509009838104,\n",
       "  0.25169068574905396,\n",
       "  0.2481580376625061,\n",
       "  0.24255767464637756,\n",
       "  0.23910923302173615,\n",
       "  0.23497651517391205,\n",
       "  0.2318245768547058,\n",
       "  0.2267872542142868],\n",
       " 'accuracy': [0.7616000175476074,\n",
       "  0.8285636305809021,\n",
       "  0.843999981880188,\n",
       "  0.8538545370101929,\n",
       "  0.8604545593261719,\n",
       "  0.8668363690376282,\n",
       "  0.8708363771438599,\n",
       "  0.8755999803543091,\n",
       "  0.8789636492729187,\n",
       "  0.8810908794403076,\n",
       "  0.8842363357543945,\n",
       "  0.8855090737342834,\n",
       "  0.8890363574028015,\n",
       "  0.8903999924659729,\n",
       "  0.8938363790512085,\n",
       "  0.8954908847808838,\n",
       "  0.8974727392196655,\n",
       "  0.8997091054916382,\n",
       "  0.9007999897003174,\n",
       "  0.9032182097434998,\n",
       "  0.9045636653900146,\n",
       "  0.9056181907653809,\n",
       "  0.9076545238494873,\n",
       "  0.9095090627670288,\n",
       "  0.9112545251846313,\n",
       "  0.9131454825401306,\n",
       "  0.9133636355400085,\n",
       "  0.9154727458953857,\n",
       "  0.9161818027496338,\n",
       "  0.918290913105011],\n",
       " 'val_loss': [0.5298005938529968,\n",
       "  0.4480077028274536,\n",
       "  0.4126698672771454,\n",
       "  0.40755099058151245,\n",
       "  0.42377084493637085,\n",
       "  0.3892292380332947,\n",
       "  0.39179641008377075,\n",
       "  0.38458847999572754,\n",
       "  0.3731241822242737,\n",
       "  0.3437618017196655,\n",
       "  0.340240478515625,\n",
       "  0.33789750933647156,\n",
       "  0.3303515911102295,\n",
       "  0.32459545135498047,\n",
       "  0.3643607795238495,\n",
       "  0.3240402936935425,\n",
       "  0.3116409182548523,\n",
       "  0.33362898230552673,\n",
       "  0.321574866771698,\n",
       "  0.32004809379577637,\n",
       "  0.30520179867744446,\n",
       "  0.31739193201065063,\n",
       "  0.30905047059059143,\n",
       "  0.30381301045417786,\n",
       "  0.30226045846939087,\n",
       "  0.30309903621673584,\n",
       "  0.31802669167518616,\n",
       "  0.2983570694923401,\n",
       "  0.32115671038627625,\n",
       "  0.30043119192123413],\n",
       " 'val_accuracy': [0.8220000267028809,\n",
       "  0.8483999967575073,\n",
       "  0.8583999872207642,\n",
       "  0.8600000143051147,\n",
       "  0.8550000190734863,\n",
       "  0.8622000217437744,\n",
       "  0.8629999756813049,\n",
       "  0.8610000014305115,\n",
       "  0.8659999966621399,\n",
       "  0.8777999877929688,\n",
       "  0.8805999755859375,\n",
       "  0.8787999749183655,\n",
       "  0.8826000094413757,\n",
       "  0.8877999782562256,\n",
       "  0.8673999905586243,\n",
       "  0.8840000033378601,\n",
       "  0.8884000182151794,\n",
       "  0.8766000270843506,\n",
       "  0.8863999843597412,\n",
       "  0.8840000033378601,\n",
       "  0.8912000060081482,\n",
       "  0.8840000033378601,\n",
       "  0.8899999856948853,\n",
       "  0.8894000053405762,\n",
       "  0.8913999795913696,\n",
       "  0.8935999870300293,\n",
       "  0.8858000040054321,\n",
       "  0.8907999992370605,\n",
       "  0.8784000277519226,\n",
       "  0.8916000127792358]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1718.75"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55000/32 # number of minibactchs of len 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 11s 1ms/step - loss: 121.0517 - accuracy: 0.8434\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[121.05171203613281, 0.8434000015258789]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]/32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_proba = model.predict(X_new)\n",
    "y_proba.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-39-5569b3de7749>:2: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict_classes(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U10')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.5666 - main_output_loss: 2.3051 - aux_output_loss: 4.9197 - val_loss: 1.4776 - val_main_output_loss: 1.2425 - val_aux_output_loss: 3.5941\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2771 - main_output_loss: 1.0861 - aux_output_loss: 2.9958 - val_loss: 1.0308 - val_main_output_loss: 0.8877 - val_aux_output_loss: 2.3184\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9870 - main_output_loss: 0.8632 - aux_output_loss: 2.1015 - val_loss: 0.8698 - val_main_output_loss: 0.7659 - val_aux_output_loss: 1.8050\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8625 - main_output_loss: 0.7638 - aux_output_loss: 1.7507 - val_loss: 0.7902 - val_main_output_loss: 0.7002 - val_aux_output_loss: 1.6006\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7976 - main_output_loss: 0.7092 - aux_output_loss: 1.5928 - val_loss: 0.7407 - val_main_output_loss: 0.6556 - val_aux_output_loss: 1.5064\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7530 - main_output_loss: 0.6693 - aux_output_loss: 1.5065 - val_loss: 0.7059 - val_main_output_loss: 0.6234 - val_aux_output_loss: 1.4483\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7190 - main_output_loss: 0.6378 - aux_output_loss: 1.4501 - val_loss: 0.6783 - val_main_output_loss: 0.5975 - val_aux_output_loss: 1.4060\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6916 - main_output_loss: 0.6122 - aux_output_loss: 1.4067 - val_loss: 0.6545 - val_main_output_loss: 0.5749 - val_aux_output_loss: 1.3707\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6683 - main_output_loss: 0.5902 - aux_output_loss: 1.3708 - val_loss: 0.6375 - val_main_output_loss: 0.5593 - val_aux_output_loss: 1.3407\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6500 - main_output_loss: 0.5733 - aux_output_loss: 1.3396 - val_loss: 0.6190 - val_main_output_loss: 0.5421 - val_aux_output_loss: 1.3113\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.6330 - main_output_loss: 0.5575 - aux_output_loss: 1.3121 - val_loss: 0.6067 - val_main_output_loss: 0.5313 - val_aux_output_loss: 1.2859\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6195 - main_output_loss: 0.5453 - aux_output_loss: 1.2871 - val_loss: 0.5930 - val_main_output_loss: 0.5187 - val_aux_output_loss: 1.2622\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6074 - main_output_loss: 0.5344 - aux_output_loss: 1.2639 - val_loss: 0.5823 - val_main_output_loss: 0.5091 - val_aux_output_loss: 1.2408\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5971 - main_output_loss: 0.5253 - aux_output_loss: 1.2433 - val_loss: 0.5763 - val_main_output_loss: 0.5047 - val_aux_output_loss: 1.2209\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5888 - main_output_loss: 0.5182 - aux_output_loss: 1.2238 - val_loss: 0.5657 - val_main_output_loss: 0.4950 - val_aux_output_loss: 1.2016\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5818 - main_output_loss: 0.5125 - aux_output_loss: 1.2055 - val_loss: 0.5588 - val_main_output_loss: 0.4895 - val_aux_output_loss: 1.1824\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5755 - main_output_loss: 0.5074 - aux_output_loss: 1.1881 - val_loss: 0.5537 - val_main_output_loss: 0.4858 - val_aux_output_loss: 1.1649\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5699 - main_output_loss: 0.5031 - aux_output_loss: 1.1712 - val_loss: 0.5489 - val_main_output_loss: 0.4824 - val_aux_output_loss: 1.1477\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5647 - main_output_loss: 0.4992 - aux_output_loss: 1.1547 - val_loss: 0.5430 - val_main_output_loss: 0.4777 - val_aux_output_loss: 1.1303\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5599 - main_output_loss: 0.4956 - aux_output_loss: 1.1387 - val_loss: 0.5418 - val_main_output_loss: 0.4782 - val_aux_output_loss: 1.1141\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5562 - main_output_loss: 0.4933 - aux_output_loss: 1.1228 - val_loss: 0.5393 - val_main_output_loss: 0.4771 - val_aux_output_loss: 1.0992\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5521 - main_output_loss: 0.4904 - aux_output_loss: 1.1075 - val_loss: 0.5310 - val_main_output_loss: 0.4697 - val_aux_output_loss: 1.0820\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5477 - main_output_loss: 0.4872 - aux_output_loss: 1.0928 - val_loss: 0.5274 - val_main_output_loss: 0.4675 - val_aux_output_loss: 1.0671\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5447 - main_output_loss: 0.4854 - aux_output_loss: 1.0782 - val_loss: 0.5231 - val_main_output_loss: 0.4643 - val_aux_output_loss: 1.0529\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5412 - main_output_loss: 0.4831 - aux_output_loss: 1.0640 - val_loss: 0.5215 - val_main_output_loss: 0.4641 - val_aux_output_loss: 1.0379\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5388 - main_output_loss: 0.4820 - aux_output_loss: 1.0504 - val_loss: 0.5177 - val_main_output_loss: 0.4615 - val_aux_output_loss: 1.0242\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5350 - main_output_loss: 0.4792 - aux_output_loss: 1.0366 - val_loss: 0.5147 - val_main_output_loss: 0.4596 - val_aux_output_loss: 1.0104\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5322 - main_output_loss: 0.4777 - aux_output_loss: 1.0233 - val_loss: 0.5124 - val_main_output_loss: 0.4585 - val_aux_output_loss: 0.9976\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5290 - main_output_loss: 0.4755 - aux_output_loss: 1.0103 - val_loss: 0.5126 - val_main_output_loss: 0.4602 - val_aux_output_loss: 0.9847\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5271 - main_output_loss: 0.4748 - aux_output_loss: 0.9977 - val_loss: 0.5075 - val_main_output_loss: 0.4560 - val_aux_output_loss: 0.9714\n"
     ]
    }
   ],
   "source": [
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "X_new_A, X_new_B = X_test[:, :5], X_test[:, 2:]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=30, validation_data=((X_valid_A, X_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 6s 1ms/step - loss: 0.4195\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test, batch_size=1)\n",
    "y_pred = model.predict((X_new_A, X_new_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "output_aux = keras.layers.Dense(1, name=\"aux_output\")(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, output_aux])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## each output needs its own loss \n",
    "model.compile(loss=[\"mse\", \"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.6321 - main_output_loss: 2.4599 - aux_output_loss: 4.1819 - val_loss: 1.3380 - val_main_output_loss: 1.1069 - val_aux_output_loss: 3.4181\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0641 - main_output_loss: 0.8542 - aux_output_loss: 2.9527 - val_loss: 0.9280 - val_main_output_loss: 0.7476 - val_aux_output_loss: 2.5509\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8510 - main_output_loss: 0.6889 - aux_output_loss: 2.3098 - val_loss: 0.8124 - val_main_output_loss: 0.6721 - val_aux_output_loss: 2.0746\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7759 - main_output_loss: 0.6452 - aux_output_loss: 1.9522 - val_loss: 0.7594 - val_main_output_loss: 0.6420 - val_aux_output_loss: 1.8166\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7361 - main_output_loss: 0.6229 - aux_output_loss: 1.7543 - val_loss: 0.7287 - val_main_output_loss: 0.6231 - val_aux_output_loss: 1.6789\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7097 - main_output_loss: 0.6069 - aux_output_loss: 1.6349 - val_loss: 0.7067 - val_main_output_loss: 0.6084 - val_aux_output_loss: 1.5910\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6894 - main_output_loss: 0.5937 - aux_output_loss: 1.5506 - val_loss: 0.6892 - val_main_output_loss: 0.5961 - val_aux_output_loss: 1.5272\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6716 - main_output_loss: 0.5810 - aux_output_loss: 1.4873 - val_loss: 0.6734 - val_main_output_loss: 0.5839 - val_aux_output_loss: 1.4789\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6556 - main_output_loss: 0.5690 - aux_output_loss: 1.4352 - val_loss: 0.6605 - val_main_output_loss: 0.5744 - val_aux_output_loss: 1.4358\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6407 - main_output_loss: 0.5570 - aux_output_loss: 1.3938 - val_loss: 0.6463 - val_main_output_loss: 0.5628 - val_aux_output_loss: 1.3980\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6278 - main_output_loss: 0.5471 - aux_output_loss: 1.3541 - val_loss: 0.6343 - val_main_output_loss: 0.5532 - val_aux_output_loss: 1.3648\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6157 - main_output_loss: 0.5373 - aux_output_loss: 1.3221 - val_loss: 0.6236 - val_main_output_loss: 0.5447 - val_aux_output_loss: 1.3339\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6063 - main_output_loss: 0.5302 - aux_output_loss: 1.2914 - val_loss: 0.6136 - val_main_output_loss: 0.5366 - val_aux_output_loss: 1.3060\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5961 - main_output_loss: 0.5218 - aux_output_loss: 1.2649 - val_loss: 0.6036 - val_main_output_loss: 0.5284 - val_aux_output_loss: 1.2801\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5870 - main_output_loss: 0.5145 - aux_output_loss: 1.2397 - val_loss: 0.5945 - val_main_output_loss: 0.5212 - val_aux_output_loss: 1.2551\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5784 - main_output_loss: 0.5075 - aux_output_loss: 1.2171 - val_loss: 0.5856 - val_main_output_loss: 0.5137 - val_aux_output_loss: 1.2320\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5708 - main_output_loss: 0.5015 - aux_output_loss: 1.1948 - val_loss: 0.5778 - val_main_output_loss: 0.5076 - val_aux_output_loss: 1.2095\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5632 - main_output_loss: 0.4955 - aux_output_loss: 1.1729 - val_loss: 0.5703 - val_main_output_loss: 0.5017 - val_aux_output_loss: 1.1876\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5563 - main_output_loss: 0.4900 - aux_output_loss: 1.1529 - val_loss: 0.5637 - val_main_output_loss: 0.4967 - val_aux_output_loss: 1.1667\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5490 - main_output_loss: 0.4841 - aux_output_loss: 1.1337 - val_loss: 0.5576 - val_main_output_loss: 0.4921 - val_aux_output_loss: 1.1472\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5439 - main_output_loss: 0.4805 - aux_output_loss: 1.1145 - val_loss: 0.5513 - val_main_output_loss: 0.4873 - val_aux_output_loss: 1.1280\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5377 - main_output_loss: 0.4756 - aux_output_loss: 1.0970 - val_loss: 0.5450 - val_main_output_loss: 0.4824 - val_aux_output_loss: 1.1086\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5322 - main_output_loss: 0.4715 - aux_output_loss: 1.0788 - val_loss: 0.5396 - val_main_output_loss: 0.4783 - val_aux_output_loss: 1.0908\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5273 - main_output_loss: 0.4679 - aux_output_loss: 1.0619 - val_loss: 0.5350 - val_main_output_loss: 0.4752 - val_aux_output_loss: 1.0734\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5221 - main_output_loss: 0.4640 - aux_output_loss: 1.0450 - val_loss: 0.5297 - val_main_output_loss: 0.4712 - val_aux_output_loss: 1.0561\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5180 - main_output_loss: 0.4612 - aux_output_loss: 1.0294 - val_loss: 0.5249 - val_main_output_loss: 0.4676 - val_aux_output_loss: 1.0402\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5127 - main_output_loss: 0.4570 - aux_output_loss: 1.0139 - val_loss: 0.5201 - val_main_output_loss: 0.4641 - val_aux_output_loss: 1.0239\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5078 - main_output_loss: 0.4532 - aux_output_loss: 0.9995 - val_loss: 0.5157 - val_main_output_loss: 0.4608 - val_aux_output_loss: 1.0096\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5043 - main_output_loss: 0.4509 - aux_output_loss: 0.9848 - val_loss: 0.5117 - val_main_output_loss: 0.4580 - val_aux_output_loss: 0.9945\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5002 - main_output_loss: 0.4480 - aux_output_loss: 0.9705 - val_loss: 0.5074 - val_main_output_loss: 0.4549 - val_aux_output_loss: 0.9803\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=30, validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 796us/step - loss: 0.5046 - main_output_loss: 0.4491 - aux_output_loss: 1.0035\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([X_test_A, X_test_B], [y_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_main, y_pred_aux = model.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9050617],\n",
       "       [0.6616001],\n",
       "       [2.1296847],\n",
       "       ...,\n",
       "       [2.7350054],\n",
       "       [3.0624657],\n",
       "       [1.9652317]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5537205],\n",
       "       [1.4857268],\n",
       "       [1.9483924],\n",
       "       ...,\n",
       "       [2.1941953],\n",
       "       [2.1259003],\n",
       "       [1.8979888]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loaded = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.9050617],\n",
       "        [0.6616001],\n",
       "        [2.1296847],\n",
       "        ...,\n",
       "        [2.7350054],\n",
       "        [3.0624657],\n",
       "        [1.9652317]], dtype=float32),\n",
       " array([[1.5537205],\n",
       "        [1.4857268],\n",
       "        [1.9483924],\n",
       "        ...,\n",
       "        [2.1941953],\n",
       "        [2.1259003],\n",
       "        [1.8979888]], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loaded.predict([X_new_A, X_new_B])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CallBacks : checkpoint, earlyStoping ad Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tensorboard log file\n",
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "  2/363 [..............................] - ETA: 2:11 - loss: 5.2667 - main_output_loss: 5.4456 - aux_output_loss: 3.6565WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_begin` time: 0.0220s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0010s vs `on_train_batch_end` time: 0.7030s). Check your callbacks.\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 5.3652 - main_output_loss: 5.5224 - aux_output_loss: 3.9506 - val_loss: 5.2074 - val_main_output_loss: 5.3535 - val_aux_output_loss: 3.8926\n",
      "Epoch 2/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 5.2206 - main_output_loss: 5.3637 - aux_output_loss: 3.9326 - val_loss: 5.0688 - val_main_output_loss: 5.2015 - val_aux_output_loss: 3.8750\n",
      "Epoch 3/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 5.0810 - main_output_loss: 5.2107 - aux_output_loss: 3.9141 - val_loss: 4.9350 - val_main_output_loss: 5.0548 - val_aux_output_loss: 3.8570\n",
      "Epoch 4/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.9461 - main_output_loss: 5.0629 - aux_output_loss: 3.8953 - val_loss: 4.8056 - val_main_output_loss: 4.9131 - val_aux_output_loss: 3.8385\n",
      "Epoch 5/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.8158 - main_output_loss: 4.9202 - aux_output_loss: 3.8759 - val_loss: 4.6804 - val_main_output_loss: 4.7761 - val_aux_output_loss: 3.8196\n",
      "Epoch 6/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.6899 - main_output_loss: 4.7825 - aux_output_loss: 3.8562 - val_loss: 4.5593 - val_main_output_loss: 4.6436 - val_aux_output_loss: 3.8002\n",
      "Epoch 7/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.5681 - main_output_loss: 4.6494 - aux_output_loss: 3.8361 - val_loss: 4.4419 - val_main_output_loss: 4.5154 - val_aux_output_loss: 3.7805\n",
      "Epoch 8/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.4503 - main_output_loss: 4.5208 - aux_output_loss: 3.8156 - val_loss: 4.3282 - val_main_output_loss: 4.3913 - val_aux_output_loss: 3.7604\n",
      "Epoch 9/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.3362 - main_output_loss: 4.3964 - aux_output_loss: 3.7947 - val_loss: 4.2181 - val_main_output_loss: 4.2712 - val_aux_output_loss: 3.7400\n",
      "Epoch 10/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.2259 - main_output_loss: 4.2761 - aux_output_loss: 3.7736 - val_loss: 4.1114 - val_main_output_loss: 4.1550 - val_aux_output_loss: 3.7193\n",
      "Epoch 11/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.1190 - main_output_loss: 4.1597 - aux_output_loss: 3.7522 - val_loss: 4.0079 - val_main_output_loss: 4.0423 - val_aux_output_loss: 3.6985\n",
      "Epoch 12/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.0154 - main_output_loss: 4.0471 - aux_output_loss: 3.7305 - val_loss: 3.9077 - val_main_output_loss: 3.9332 - val_aux_output_loss: 3.6776\n",
      "Epoch 13/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.9152 - main_output_loss: 3.9381 - aux_output_loss: 3.7086 - val_loss: 3.8105 - val_main_output_loss: 3.8276 - val_aux_output_loss: 3.6564\n",
      "Epoch 14/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.8180 - main_output_loss: 3.8326 - aux_output_loss: 3.6866 - val_loss: 3.7162 - val_main_output_loss: 3.7253 - val_aux_output_loss: 3.6350\n",
      "Epoch 15/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.7239 - main_output_loss: 3.7305 - aux_output_loss: 3.6643 - val_loss: 3.6249 - val_main_output_loss: 3.6261 - val_aux_output_loss: 3.6135\n",
      "Epoch 16/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.6327 - main_output_loss: 3.6317 - aux_output_loss: 3.6418 - val_loss: 3.5363 - val_main_output_loss: 3.5302 - val_aux_output_loss: 3.5918\n",
      "Epoch 17/200\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 3.5445 - main_output_loss: 3.5362 - aux_output_loss: 3.6193 - val_loss: 3.4504 - val_main_output_loss: 3.4372 - val_aux_output_loss: 3.5699\n",
      "Epoch 18/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.4590 - main_output_loss: 3.4437 - aux_output_loss: 3.5967 - val_loss: 3.3672 - val_main_output_loss: 3.3471 - val_aux_output_loss: 3.5480\n",
      "Epoch 19/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.3761 - main_output_loss: 3.3542 - aux_output_loss: 3.5740 - val_loss: 3.2865 - val_main_output_loss: 3.2599 - val_aux_output_loss: 3.5260\n",
      "Epoch 20/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.2960 - main_output_loss: 3.2677 - aux_output_loss: 3.5511 - val_loss: 3.2084 - val_main_output_loss: 3.1756 - val_aux_output_loss: 3.5039\n",
      "Epoch 21/200\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 3.2185 - main_output_loss: 3.1841 - aux_output_loss: 3.5284 - val_loss: 3.1328 - val_main_output_loss: 3.0940 - val_aux_output_loss: 3.4819\n",
      "Epoch 22/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.1436 - main_output_loss: 3.1034 - aux_output_loss: 3.5056 - val_loss: 3.0595 - val_main_output_loss: 3.0151 - val_aux_output_loss: 3.4598\n",
      "Epoch 23/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.0712 - main_output_loss: 3.0254 - aux_output_loss: 3.4829 - val_loss: 2.9887 - val_main_output_loss: 2.9389 - val_aux_output_loss: 3.4378\n",
      "Epoch 24/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.0012 - main_output_loss: 2.9501 - aux_output_loss: 3.4602 - val_loss: 2.9202 - val_main_output_loss: 2.8651 - val_aux_output_loss: 3.4158\n",
      "Epoch 25/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.9335 - main_output_loss: 2.8775 - aux_output_loss: 3.4374 - val_loss: 2.8539 - val_main_output_loss: 2.7940 - val_aux_output_loss: 3.3938\n",
      "Epoch 26/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.8681 - main_output_loss: 2.8073 - aux_output_loss: 3.4150 - val_loss: 2.7899 - val_main_output_loss: 2.7252 - val_aux_output_loss: 3.3719\n",
      "Epoch 27/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.8049 - main_output_loss: 2.7396 - aux_output_loss: 3.3925 - val_loss: 2.7280 - val_main_output_loss: 2.6589 - val_aux_output_loss: 3.3502\n",
      "Epoch 28/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.7440 - main_output_loss: 2.6745 - aux_output_loss: 3.3703 - val_loss: 2.6682 - val_main_output_loss: 2.5948 - val_aux_output_loss: 3.3285\n",
      "Epoch 29/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.6853 - main_output_loss: 2.6116 - aux_output_loss: 3.3482 - val_loss: 2.6105 - val_main_output_loss: 2.5331 - val_aux_output_loss: 3.3070\n",
      "Epoch 30/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.6287 - main_output_loss: 2.5511 - aux_output_loss: 3.3262 - val_loss: 2.5548 - val_main_output_loss: 2.4736 - val_aux_output_loss: 3.2857\n",
      "Epoch 31/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.5741 - main_output_loss: 2.4930 - aux_output_loss: 3.3045 - val_loss: 2.5011 - val_main_output_loss: 2.4162 - val_aux_output_loss: 3.2645\n",
      "Epoch 32/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.5215 - main_output_loss: 2.4369 - aux_output_loss: 3.2830 - val_loss: 2.4493 - val_main_output_loss: 2.3611 - val_aux_output_loss: 3.2436\n",
      "Epoch 33/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.4709 - main_output_loss: 2.3830 - aux_output_loss: 3.2618 - val_loss: 2.3995 - val_main_output_loss: 2.3080 - val_aux_output_loss: 3.2229\n",
      "Epoch 34/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.4222 - main_output_loss: 2.3312 - aux_output_loss: 3.2406 - val_loss: 2.3515 - val_main_output_loss: 2.2570 - val_aux_output_loss: 3.2025\n",
      "Epoch 35/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.3753 - main_output_loss: 2.2815 - aux_output_loss: 3.2197 - val_loss: 2.3054 - val_main_output_loss: 2.2079 - val_aux_output_loss: 3.1823\n",
      "Epoch 36/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.3302 - main_output_loss: 2.2336 - aux_output_loss: 3.1991 - val_loss: 2.2609 - val_main_output_loss: 2.1608 - val_aux_output_loss: 3.1623\n",
      "Epoch 37/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.2868 - main_output_loss: 2.1877 - aux_output_loss: 3.1789 - val_loss: 2.2181 - val_main_output_loss: 2.1154 - val_aux_output_loss: 3.1425\n",
      "Epoch 38/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.2450 - main_output_loss: 2.1435 - aux_output_loss: 3.1587 - val_loss: 2.1770 - val_main_output_loss: 2.0719 - val_aux_output_loss: 3.1230\n",
      "Epoch 39/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.2048 - main_output_loss: 2.1011 - aux_output_loss: 3.1387 - val_loss: 2.1374 - val_main_output_loss: 2.0300 - val_aux_output_loss: 3.1037\n",
      "Epoch 40/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.1662 - main_output_loss: 2.0603 - aux_output_loss: 3.1192 - val_loss: 2.0993 - val_main_output_loss: 1.9898 - val_aux_output_loss: 3.0847\n",
      "Epoch 41/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.1291 - main_output_loss: 2.0212 - aux_output_loss: 3.1001 - val_loss: 2.0627 - val_main_output_loss: 1.9512 - val_aux_output_loss: 3.0659\n",
      "Epoch 42/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.0934 - main_output_loss: 1.9837 - aux_output_loss: 3.0810 - val_loss: 2.0275 - val_main_output_loss: 1.9142 - val_aux_output_loss: 3.0473\n",
      "Epoch 43/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.0591 - main_output_loss: 1.9477 - aux_output_loss: 3.0624 - val_loss: 1.9937 - val_main_output_loss: 1.8786 - val_aux_output_loss: 3.0290\n",
      "Epoch 44/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.0262 - main_output_loss: 1.9131 - aux_output_loss: 3.0440 - val_loss: 1.9612 - val_main_output_loss: 1.8445 - val_aux_output_loss: 3.0110\n",
      "Epoch 45/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.9945 - main_output_loss: 1.8799 - aux_output_loss: 3.0260 - val_loss: 1.9300 - val_main_output_loss: 1.8118 - val_aux_output_loss: 2.9933\n",
      "Epoch 46/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.9641 - main_output_loss: 1.8481 - aux_output_loss: 3.0080 - val_loss: 1.9000 - val_main_output_loss: 1.7804 - val_aux_output_loss: 2.9758\n",
      "Epoch 47/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.9349 - main_output_loss: 1.8176 - aux_output_loss: 2.9902 - val_loss: 1.8712 - val_main_output_loss: 1.7503 - val_aux_output_loss: 2.9585\n",
      "Epoch 48/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.9068 - main_output_loss: 1.7884 - aux_output_loss: 2.9729 - val_loss: 1.8435 - val_main_output_loss: 1.7215 - val_aux_output_loss: 2.9415\n",
      "Epoch 49/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.8798 - main_output_loss: 1.7603 - aux_output_loss: 2.9559 - val_loss: 1.8169 - val_main_output_loss: 1.6938 - val_aux_output_loss: 2.9248\n",
      "Epoch 50/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.8539 - main_output_loss: 1.7333 - aux_output_loss: 2.9391 - val_loss: 1.7913 - val_main_output_loss: 1.6672 - val_aux_output_loss: 2.9083\n",
      "Epoch 51/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.8289 - main_output_loss: 1.7074 - aux_output_loss: 2.9227 - val_loss: 1.7667 - val_main_output_loss: 1.6417 - val_aux_output_loss: 2.8920\n",
      "Epoch 52/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.8049 - main_output_loss: 1.6825 - aux_output_loss: 2.9062 - val_loss: 1.7431 - val_main_output_loss: 1.6172 - val_aux_output_loss: 2.8760\n",
      "Epoch 53/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7818 - main_output_loss: 1.6586 - aux_output_loss: 2.8903 - val_loss: 1.7203 - val_main_output_loss: 1.5937 - val_aux_output_loss: 2.8603\n",
      "Epoch 54/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7596 - main_output_loss: 1.6357 - aux_output_loss: 2.8744 - val_loss: 1.6985 - val_main_output_loss: 1.5711 - val_aux_output_loss: 2.8448\n",
      "Epoch 55/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7382 - main_output_loss: 1.6137 - aux_output_loss: 2.8588 - val_loss: 1.6774 - val_main_output_loss: 1.5494 - val_aux_output_loss: 2.8295\n",
      "Epoch 56/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7176 - main_output_loss: 1.5925 - aux_output_loss: 2.8436 - val_loss: 1.6572 - val_main_output_loss: 1.5286 - val_aux_output_loss: 2.8145\n",
      "Epoch 57/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.6977 - main_output_loss: 1.5721 - aux_output_loss: 2.8287 - val_loss: 1.6377 - val_main_output_loss: 1.5086 - val_aux_output_loss: 2.7997\n",
      "Epoch 58/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.6786 - main_output_loss: 1.5525 - aux_output_loss: 2.8137 - val_loss: 1.6190 - val_main_output_loss: 1.4894 - val_aux_output_loss: 2.7851\n",
      "Epoch 59/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.6601 - main_output_loss: 1.5336 - aux_output_loss: 2.7991 - val_loss: 1.6009 - val_main_output_loss: 1.4709 - val_aux_output_loss: 2.7707\n",
      "Epoch 60/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.6424 - main_output_loss: 1.5155 - aux_output_loss: 2.7846 - val_loss: 1.5835 - val_main_output_loss: 1.4532 - val_aux_output_loss: 2.7566\n",
      "Epoch 61/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.6252 - main_output_loss: 1.4980 - aux_output_loss: 2.7705 - val_loss: 1.5668 - val_main_output_loss: 1.4361 - val_aux_output_loss: 2.7427\n",
      "Epoch 62/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.6087 - main_output_loss: 1.4811 - aux_output_loss: 2.7566 - val_loss: 1.5506 - val_main_output_loss: 1.4197 - val_aux_output_loss: 2.7290\n",
      "Epoch 63/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5927 - main_output_loss: 1.4649 - aux_output_loss: 2.7430 - val_loss: 1.5350 - val_main_output_loss: 1.4038 - val_aux_output_loss: 2.7155\n",
      "Epoch 64/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5772 - main_output_loss: 1.4492 - aux_output_loss: 2.7295 - val_loss: 1.5200 - val_main_output_loss: 1.3886 - val_aux_output_loss: 2.7023\n",
      "Epoch 65/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5623 - main_output_loss: 1.4341 - aux_output_loss: 2.7162 - val_loss: 1.5054 - val_main_output_loss: 1.3739 - val_aux_output_loss: 2.6892\n",
      "Epoch 66/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5478 - main_output_loss: 1.4195 - aux_output_loss: 2.7032 - val_loss: 1.4914 - val_main_output_loss: 1.3598 - val_aux_output_loss: 2.6763\n",
      "Epoch 67/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5339 - main_output_loss: 1.4054 - aux_output_loss: 2.6903 - val_loss: 1.4779 - val_main_output_loss: 1.3461 - val_aux_output_loss: 2.6636\n",
      "Epoch 68/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5204 - main_output_loss: 1.3918 - aux_output_loss: 2.6776 - val_loss: 1.4648 - val_main_output_loss: 1.3330 - val_aux_output_loss: 2.6511\n",
      "Epoch 69/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.5073 - main_output_loss: 1.3786 - aux_output_loss: 2.6649 - val_loss: 1.4521 - val_main_output_loss: 1.3203 - val_aux_output_loss: 2.6388\n",
      "Epoch 70/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4946 - main_output_loss: 1.3659 - aux_output_loss: 2.6526 - val_loss: 1.4399 - val_main_output_loss: 1.3080 - val_aux_output_loss: 2.6267\n",
      "Epoch 71/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4823 - main_output_loss: 1.3536 - aux_output_loss: 2.6406 - val_loss: 1.4280 - val_main_output_loss: 1.2962 - val_aux_output_loss: 2.6148\n",
      "Epoch 72/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4704 - main_output_loss: 1.3417 - aux_output_loss: 2.6287 - val_loss: 1.4165 - val_main_output_loss: 1.2847 - val_aux_output_loss: 2.6030\n",
      "Epoch 73/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4588 - main_output_loss: 1.3301 - aux_output_loss: 2.6170 - val_loss: 1.4054 - val_main_output_loss: 1.2736 - val_aux_output_loss: 2.5914\n",
      "Epoch 74/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4476 - main_output_loss: 1.3190 - aux_output_loss: 2.6053 - val_loss: 1.3946 - val_main_output_loss: 1.2629 - val_aux_output_loss: 2.5799\n",
      "Epoch 75/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4367 - main_output_loss: 1.3081 - aux_output_loss: 2.5939 - val_loss: 1.3842 - val_main_output_loss: 1.2526 - val_aux_output_loss: 2.5686\n",
      "Epoch 76/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4261 - main_output_loss: 1.2977 - aux_output_loss: 2.5823 - val_loss: 1.3740 - val_main_output_loss: 1.2425 - val_aux_output_loss: 2.5575\n",
      "Epoch 77/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4159 - main_output_loss: 1.2875 - aux_output_loss: 2.5713 - val_loss: 1.3642 - val_main_output_loss: 1.2328 - val_aux_output_loss: 2.5465\n",
      "Epoch 78/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4058 - main_output_loss: 1.2776 - aux_output_loss: 2.5603 - val_loss: 1.3546 - val_main_output_loss: 1.2234 - val_aux_output_loss: 2.5357\n",
      "Epoch 79/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3961 - main_output_loss: 1.2680 - aux_output_loss: 2.5494 - val_loss: 1.3453 - val_main_output_loss: 1.2142 - val_aux_output_loss: 2.5251\n",
      "Epoch 80/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3867 - main_output_loss: 1.2587 - aux_output_loss: 2.5387 - val_loss: 1.3363 - val_main_output_loss: 1.2054 - val_aux_output_loss: 2.5145\n",
      "Epoch 81/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3775 - main_output_loss: 1.2496 - aux_output_loss: 2.5282 - val_loss: 1.3275 - val_main_output_loss: 1.1968 - val_aux_output_loss: 2.5042\n",
      "Epoch 82/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3685 - main_output_loss: 1.2408 - aux_output_loss: 2.5178 - val_loss: 1.3190 - val_main_output_loss: 1.1884 - val_aux_output_loss: 2.4939\n",
      "Epoch 83/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3597 - main_output_loss: 1.2322 - aux_output_loss: 2.5076 - val_loss: 1.3107 - val_main_output_loss: 1.1803 - val_aux_output_loss: 2.4838\n",
      "Epoch 84/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3512 - main_output_loss: 1.2239 - aux_output_loss: 2.4973 - val_loss: 1.3026 - val_main_output_loss: 1.1725 - val_aux_output_loss: 2.4739\n",
      "Epoch 85/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3429 - main_output_loss: 1.2157 - aux_output_loss: 2.4874 - val_loss: 1.2947 - val_main_output_loss: 1.1648 - val_aux_output_loss: 2.4641\n",
      "Epoch 86/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3348 - main_output_loss: 1.2078 - aux_output_loss: 2.4775 - val_loss: 1.2871 - val_main_output_loss: 1.1574 - val_aux_output_loss: 2.4544\n",
      "Epoch 87/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3269 - main_output_loss: 1.2001 - aux_output_loss: 2.4678 - val_loss: 1.2796 - val_main_output_loss: 1.1501 - val_aux_output_loss: 2.4448\n",
      "Epoch 88/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3192 - main_output_loss: 1.1926 - aux_output_loss: 2.4581 - val_loss: 1.2723 - val_main_output_loss: 1.1431 - val_aux_output_loss: 2.4353\n",
      "Epoch 89/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3117 - main_output_loss: 1.1853 - aux_output_loss: 2.4488 - val_loss: 1.2652 - val_main_output_loss: 1.1363 - val_aux_output_loss: 2.4259\n",
      "Epoch 90/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.3043 - main_output_loss: 1.1782 - aux_output_loss: 2.4392 - val_loss: 1.2583 - val_main_output_loss: 1.1296 - val_aux_output_loss: 2.4167\n",
      "Epoch 91/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2972 - main_output_loss: 1.1713 - aux_output_loss: 2.4299 - val_loss: 1.2515 - val_main_output_loss: 1.1231 - val_aux_output_loss: 2.4076\n",
      "Epoch 92/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2901 - main_output_loss: 1.1645 - aux_output_loss: 2.4207 - val_loss: 1.2449 - val_main_output_loss: 1.1167 - val_aux_output_loss: 2.3986\n",
      "Epoch 93/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2833 - main_output_loss: 1.1579 - aux_output_loss: 2.4117 - val_loss: 1.2385 - val_main_output_loss: 1.1106 - val_aux_output_loss: 2.3898\n",
      "Epoch 94/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2766 - main_output_loss: 1.1515 - aux_output_loss: 2.4027 - val_loss: 1.2322 - val_main_output_loss: 1.1046 - val_aux_output_loss: 2.3810\n",
      "Epoch 95/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2701 - main_output_loss: 1.1452 - aux_output_loss: 2.3938 - val_loss: 1.2261 - val_main_output_loss: 1.0987 - val_aux_output_loss: 2.3723\n",
      "Epoch 96/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2637 - main_output_loss: 1.1391 - aux_output_loss: 2.3851 - val_loss: 1.2200 - val_main_output_loss: 1.0929 - val_aux_output_loss: 2.3638\n",
      "Epoch 97/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2575 - main_output_loss: 1.1331 - aux_output_loss: 2.3765 - val_loss: 1.2141 - val_main_output_loss: 1.0873 - val_aux_output_loss: 2.3553\n",
      "Epoch 98/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2513 - main_output_loss: 1.1273 - aux_output_loss: 2.3679 - val_loss: 1.2085 - val_main_output_loss: 1.0820 - val_aux_output_loss: 2.3471\n",
      "Epoch 99/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2453 - main_output_loss: 1.1215 - aux_output_loss: 2.3595 - val_loss: 1.2029 - val_main_output_loss: 1.0767 - val_aux_output_loss: 2.3391\n",
      "Epoch 100/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2395 - main_output_loss: 1.1159 - aux_output_loss: 2.3513 - val_loss: 1.1975 - val_main_output_loss: 1.0716 - val_aux_output_loss: 2.3311\n",
      "Epoch 101/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2337 - main_output_loss: 1.1104 - aux_output_loss: 2.3430 - val_loss: 1.1922 - val_main_output_loss: 1.0665 - val_aux_output_loss: 2.3232\n",
      "Epoch 102/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2280 - main_output_loss: 1.1051 - aux_output_loss: 2.3347 - val_loss: 1.1870 - val_main_output_loss: 1.0616 - val_aux_output_loss: 2.3154\n",
      "Epoch 103/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2225 - main_output_loss: 1.0998 - aux_output_loss: 2.3267 - val_loss: 1.1819 - val_main_output_loss: 1.0568 - val_aux_output_loss: 2.3077\n",
      "Epoch 104/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2170 - main_output_loss: 1.0946 - aux_output_loss: 2.3187 - val_loss: 1.1768 - val_main_output_loss: 1.0520 - val_aux_output_loss: 2.3001\n",
      "Epoch 105/200\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2117 - main_output_loss: 1.0896 - aux_output_loss: 2.3108 - val_loss: 1.1719 - val_main_output_loss: 1.0474 - val_aux_output_loss: 2.2926\n",
      "Epoch 106/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2065 - main_output_loss: 1.0846 - aux_output_loss: 2.3031 - val_loss: 1.1670 - val_main_output_loss: 1.0428 - val_aux_output_loss: 2.2852\n",
      "Epoch 107/200\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.2013 - main_output_loss: 1.0797 - aux_output_loss: 2.2954 - val_loss: 1.1623 - val_main_output_loss: 1.0383 - val_aux_output_loss: 2.2778\n",
      "Epoch 108/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1963 - main_output_loss: 1.0750 - aux_output_loss: 2.2877 - val_loss: 1.1576 - val_main_output_loss: 1.0339 - val_aux_output_loss: 2.2705\n",
      "Epoch 109/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1913 - main_output_loss: 1.0703 - aux_output_loss: 2.2803 - val_loss: 1.1530 - val_main_output_loss: 1.0296 - val_aux_output_loss: 2.2633\n",
      "Epoch 110/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1864 - main_output_loss: 1.0657 - aux_output_loss: 2.2728 - val_loss: 1.1485 - val_main_output_loss: 1.0254 - val_aux_output_loss: 2.2562\n",
      "Epoch 111/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1816 - main_output_loss: 1.0612 - aux_output_loss: 2.2654 - val_loss: 1.1440 - val_main_output_loss: 1.0212 - val_aux_output_loss: 2.2492\n",
      "Epoch 112/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1769 - main_output_loss: 1.0567 - aux_output_loss: 2.2582 - val_loss: 1.1396 - val_main_output_loss: 1.0171 - val_aux_output_loss: 2.2422\n",
      "Epoch 113/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1722 - main_output_loss: 1.0524 - aux_output_loss: 2.2510 - val_loss: 1.1353 - val_main_output_loss: 1.0131 - val_aux_output_loss: 2.2354\n",
      "Epoch 114/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1677 - main_output_loss: 1.0481 - aux_output_loss: 2.2438 - val_loss: 1.1311 - val_main_output_loss: 1.0092 - val_aux_output_loss: 2.2285\n",
      "Epoch 115/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1632 - main_output_loss: 1.0439 - aux_output_loss: 2.2368 - val_loss: 1.1269 - val_main_output_loss: 1.0053 - val_aux_output_loss: 2.2218\n",
      "Epoch 116/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1588 - main_output_loss: 1.0398 - aux_output_loss: 2.2298 - val_loss: 1.1228 - val_main_output_loss: 1.0015 - val_aux_output_loss: 2.2151\n",
      "Epoch 117/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1545 - main_output_loss: 1.0358 - aux_output_loss: 2.2229 - val_loss: 1.1188 - val_main_output_loss: 0.9977 - val_aux_output_loss: 2.2085\n",
      "Epoch 118/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1502 - main_output_loss: 1.0318 - aux_output_loss: 2.2160 - val_loss: 1.1148 - val_main_output_loss: 0.9940 - val_aux_output_loss: 2.2019\n",
      "Epoch 119/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1461 - main_output_loss: 1.0280 - aux_output_loss: 2.2092 - val_loss: 1.1109 - val_main_output_loss: 0.9904 - val_aux_output_loss: 2.1954\n",
      "Epoch 120/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1420 - main_output_loss: 1.0242 - aux_output_loss: 2.2025 - val_loss: 1.1070 - val_main_output_loss: 0.9868 - val_aux_output_loss: 2.1889\n",
      "Epoch 121/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1380 - main_output_loss: 1.0204 - aux_output_loss: 2.1960 - val_loss: 1.1032 - val_main_output_loss: 0.9833 - val_aux_output_loss: 2.1825\n",
      "Epoch 122/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1340 - main_output_loss: 1.0168 - aux_output_loss: 2.1894 - val_loss: 1.0994 - val_main_output_loss: 0.9798 - val_aux_output_loss: 2.1762\n",
      "Epoch 123/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1301 - main_output_loss: 1.0131 - aux_output_loss: 2.1830 - val_loss: 1.0957 - val_main_output_loss: 0.9764 - val_aux_output_loss: 2.1700\n",
      "Epoch 124/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1263 - main_output_loss: 1.0096 - aux_output_loss: 2.1765 - val_loss: 1.0921 - val_main_output_loss: 0.9730 - val_aux_output_loss: 2.1638\n",
      "Epoch 125/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1225 - main_output_loss: 1.0061 - aux_output_loss: 2.1702 - val_loss: 1.0885 - val_main_output_loss: 0.9697 - val_aux_output_loss: 2.1577\n",
      "Epoch 126/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1187 - main_output_loss: 1.0026 - aux_output_loss: 2.1639 - val_loss: 1.0849 - val_main_output_loss: 0.9664 - val_aux_output_loss: 2.1516\n",
      "Epoch 127/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1150 - main_output_loss: 0.9992 - aux_output_loss: 2.1577 - val_loss: 1.0814 - val_main_output_loss: 0.9631 - val_aux_output_loss: 2.1456\n",
      "Epoch 128/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1114 - main_output_loss: 0.9958 - aux_output_loss: 2.1515 - val_loss: 1.0779 - val_main_output_loss: 0.9600 - val_aux_output_loss: 2.1397\n",
      "Epoch 129/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1078 - main_output_loss: 0.9925 - aux_output_loss: 2.1454 - val_loss: 1.0745 - val_main_output_loss: 0.9568 - val_aux_output_loss: 2.1338\n",
      "Epoch 130/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1043 - main_output_loss: 0.9892 - aux_output_loss: 2.1394 - val_loss: 1.0712 - val_main_output_loss: 0.9537 - val_aux_output_loss: 2.1280\n",
      "Epoch 131/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1008 - main_output_loss: 0.9860 - aux_output_loss: 2.1335 - val_loss: 1.0678 - val_main_output_loss: 0.9507 - val_aux_output_loss: 2.1222\n",
      "Epoch 132/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0973 - main_output_loss: 0.9829 - aux_output_loss: 2.1276 - val_loss: 1.0645 - val_main_output_loss: 0.9477 - val_aux_output_loss: 2.1165\n",
      "Epoch 133/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0939 - main_output_loss: 0.9797 - aux_output_loss: 2.1217 - val_loss: 1.0613 - val_main_output_loss: 0.9447 - val_aux_output_loss: 2.1109\n",
      "Epoch 134/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0906 - main_output_loss: 0.9766 - aux_output_loss: 2.1159 - val_loss: 1.0581 - val_main_output_loss: 0.9418 - val_aux_output_loss: 2.1053\n",
      "Epoch 135/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0872 - main_output_loss: 0.9736 - aux_output_loss: 2.1101 - val_loss: 1.0549 - val_main_output_loss: 0.9389 - val_aux_output_loss: 2.0997\n",
      "Epoch 136/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0840 - main_output_loss: 0.9706 - aux_output_loss: 2.1046 - val_loss: 1.0518 - val_main_output_loss: 0.9360 - val_aux_output_loss: 2.0942\n",
      "Epoch 137/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0807 - main_output_loss: 0.9676 - aux_output_loss: 2.0989 - val_loss: 1.0487 - val_main_output_loss: 0.9332 - val_aux_output_loss: 2.0888\n",
      "Epoch 138/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0776 - main_output_loss: 0.9647 - aux_output_loss: 2.0932 - val_loss: 1.0457 - val_main_output_loss: 0.9304 - val_aux_output_loss: 2.0834\n",
      "Epoch 139/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0744 - main_output_loss: 0.9618 - aux_output_loss: 2.0878 - val_loss: 1.0427 - val_main_output_loss: 0.9276 - val_aux_output_loss: 2.0781\n",
      "Epoch 140/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0713 - main_output_loss: 0.9589 - aux_output_loss: 2.0824 - val_loss: 1.0397 - val_main_output_loss: 0.9249 - val_aux_output_loss: 2.0728\n",
      "Epoch 141/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0682 - main_output_loss: 0.9561 - aux_output_loss: 2.0770 - val_loss: 1.0368 - val_main_output_loss: 0.9222 - val_aux_output_loss: 2.0675\n",
      "Epoch 142/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0652 - main_output_loss: 0.9534 - aux_output_loss: 2.0716 - val_loss: 1.0339 - val_main_output_loss: 0.9196 - val_aux_output_loss: 2.0623\n",
      "Epoch 143/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0622 - main_output_loss: 0.9506 - aux_output_loss: 2.0662 - val_loss: 1.0310 - val_main_output_loss: 0.9170 - val_aux_output_loss: 2.0572\n",
      "Epoch 144/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0592 - main_output_loss: 0.9479 - aux_output_loss: 2.0610 - val_loss: 1.0282 - val_main_output_loss: 0.9144 - val_aux_output_loss: 2.0521\n",
      "Epoch 145/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0563 - main_output_loss: 0.9453 - aux_output_loss: 2.0557 - val_loss: 1.0254 - val_main_output_loss: 0.9118 - val_aux_output_loss: 2.0471\n",
      "Epoch 146/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0534 - main_output_loss: 0.9426 - aux_output_loss: 2.0506 - val_loss: 1.0226 - val_main_output_loss: 0.9093 - val_aux_output_loss: 2.0421\n",
      "Epoch 147/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0506 - main_output_loss: 0.9400 - aux_output_loss: 2.0454 - val_loss: 1.0198 - val_main_output_loss: 0.9068 - val_aux_output_loss: 2.0371\n",
      "Epoch 148/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0478 - main_output_loss: 0.9375 - aux_output_loss: 2.0403 - val_loss: 1.0171 - val_main_output_loss: 0.9043 - val_aux_output_loss: 2.0322\n",
      "Epoch 149/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0450 - main_output_loss: 0.9349 - aux_output_loss: 2.0353 - val_loss: 1.0144 - val_main_output_loss: 0.9019 - val_aux_output_loss: 2.0274\n",
      "Epoch 150/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0422 - main_output_loss: 0.9324 - aux_output_loss: 2.0303 - val_loss: 1.0118 - val_main_output_loss: 0.8995 - val_aux_output_loss: 2.0226\n",
      "Epoch 151/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0395 - main_output_loss: 0.9300 - aux_output_loss: 2.0253 - val_loss: 1.0092 - val_main_output_loss: 0.8971 - val_aux_output_loss: 2.0178\n",
      "Epoch 152/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0368 - main_output_loss: 0.9275 - aux_output_loss: 2.0204 - val_loss: 1.0066 - val_main_output_loss: 0.8947 - val_aux_output_loss: 2.0131\n",
      "Epoch 153/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0342 - main_output_loss: 0.9251 - aux_output_loss: 2.0156 - val_loss: 1.0040 - val_main_output_loss: 0.8924 - val_aux_output_loss: 2.0084\n",
      "Epoch 154/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0315 - main_output_loss: 0.9227 - aux_output_loss: 2.0107 - val_loss: 1.0015 - val_main_output_loss: 0.8901 - val_aux_output_loss: 2.0037\n",
      "Epoch 155/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0289 - main_output_loss: 0.9204 - aux_output_loss: 2.0060 - val_loss: 0.9990 - val_main_output_loss: 0.8878 - val_aux_output_loss: 1.9991\n",
      "Epoch 156/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0263 - main_output_loss: 0.9180 - aux_output_loss: 2.0012 - val_loss: 0.9965 - val_main_output_loss: 0.8856 - val_aux_output_loss: 1.9946\n",
      "Epoch 157/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0238 - main_output_loss: 0.9157 - aux_output_loss: 1.9966 - val_loss: 0.9940 - val_main_output_loss: 0.8834 - val_aux_output_loss: 1.9900\n",
      "Epoch 158/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0213 - main_output_loss: 0.9134 - aux_output_loss: 1.9920 - val_loss: 0.9916 - val_main_output_loss: 0.8811 - val_aux_output_loss: 1.9856\n",
      "Epoch 159/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0188 - main_output_loss: 0.9112 - aux_output_loss: 1.9874 - val_loss: 0.9892 - val_main_output_loss: 0.8790 - val_aux_output_loss: 1.9811\n",
      "Epoch 160/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0163 - main_output_loss: 0.9090 - aux_output_loss: 1.9828 - val_loss: 0.9868 - val_main_output_loss: 0.8768 - val_aux_output_loss: 1.9767\n",
      "Epoch 161/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0139 - main_output_loss: 0.9068 - aux_output_loss: 1.9782 - val_loss: 0.9844 - val_main_output_loss: 0.8747 - val_aux_output_loss: 1.9723\n",
      "Epoch 162/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0115 - main_output_loss: 0.9046 - aux_output_loss: 1.9737 - val_loss: 0.9821 - val_main_output_loss: 0.8726 - val_aux_output_loss: 1.9680\n",
      "Epoch 163/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0091 - main_output_loss: 0.9024 - aux_output_loss: 1.9693 - val_loss: 0.9798 - val_main_output_loss: 0.8705 - val_aux_output_loss: 1.9637\n",
      "Epoch 164/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0068 - main_output_loss: 0.9003 - aux_output_loss: 1.9650 - val_loss: 0.9775 - val_main_output_loss: 0.8684 - val_aux_output_loss: 1.9594\n",
      "Epoch 165/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0044 - main_output_loss: 0.8982 - aux_output_loss: 1.9606 - val_loss: 0.9752 - val_main_output_loss: 0.8663 - val_aux_output_loss: 1.9552\n",
      "Epoch 166/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0021 - main_output_loss: 0.8961 - aux_output_loss: 1.9563 - val_loss: 0.9730 - val_main_output_loss: 0.8643 - val_aux_output_loss: 1.9510\n",
      "Epoch 167/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9998 - main_output_loss: 0.8940 - aux_output_loss: 1.9520 - val_loss: 0.9708 - val_main_output_loss: 0.8623 - val_aux_output_loss: 1.9469\n",
      "Epoch 168/200\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.9976 - main_output_loss: 0.8920 - aux_output_loss: 1.9477 - val_loss: 0.9686 - val_main_output_loss: 0.8603 - val_aux_output_loss: 1.9427\n",
      "Epoch 169/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9953 - main_output_loss: 0.8900 - aux_output_loss: 1.9435 - val_loss: 0.9664 - val_main_output_loss: 0.8584 - val_aux_output_loss: 1.9386\n",
      "Epoch 170/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9931 - main_output_loss: 0.8880 - aux_output_loss: 1.9393 - val_loss: 0.9642 - val_main_output_loss: 0.8564 - val_aux_output_loss: 1.9346\n",
      "Epoch 171/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9909 - main_output_loss: 0.8860 - aux_output_loss: 1.9352 - val_loss: 0.9621 - val_main_output_loss: 0.8545 - val_aux_output_loss: 1.9305\n",
      "Epoch 172/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9887 - main_output_loss: 0.8840 - aux_output_loss: 1.9311 - val_loss: 0.9600 - val_main_output_loss: 0.8526 - val_aux_output_loss: 1.9265\n",
      "Epoch 173/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9866 - main_output_loss: 0.8821 - aux_output_loss: 1.9270 - val_loss: 0.9579 - val_main_output_loss: 0.8507 - val_aux_output_loss: 1.9226\n",
      "Epoch 174/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9845 - main_output_loss: 0.8802 - aux_output_loss: 1.9229 - val_loss: 0.9558 - val_main_output_loss: 0.8488 - val_aux_output_loss: 1.9186\n",
      "Epoch 175/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9823 - main_output_loss: 0.8783 - aux_output_loss: 1.9189 - val_loss: 0.9537 - val_main_output_loss: 0.8470 - val_aux_output_loss: 1.9147\n",
      "Epoch 176/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9803 - main_output_loss: 0.8764 - aux_output_loss: 1.9149 - val_loss: 0.9517 - val_main_output_loss: 0.8451 - val_aux_output_loss: 1.9108\n",
      "Epoch 177/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9782 - main_output_loss: 0.8746 - aux_output_loss: 1.9110 - val_loss: 0.9497 - val_main_output_loss: 0.8433 - val_aux_output_loss: 1.9070\n",
      "Epoch 178/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9761 - main_output_loss: 0.8727 - aux_output_loss: 1.9071 - val_loss: 0.9477 - val_main_output_loss: 0.8415 - val_aux_output_loss: 1.9032\n",
      "Epoch 179/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9741 - main_output_loss: 0.8709 - aux_output_loss: 1.9033 - val_loss: 0.9457 - val_main_output_loss: 0.8397 - val_aux_output_loss: 1.8994\n",
      "Epoch 180/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9721 - main_output_loss: 0.8691 - aux_output_loss: 1.8993 - val_loss: 0.9437 - val_main_output_loss: 0.8380 - val_aux_output_loss: 1.8957\n",
      "Epoch 181/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9701 - main_output_loss: 0.8673 - aux_output_loss: 1.8955 - val_loss: 0.9418 - val_main_output_loss: 0.8362 - val_aux_output_loss: 1.8919\n",
      "Epoch 182/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9681 - main_output_loss: 0.8655 - aux_output_loss: 1.8917 - val_loss: 0.9399 - val_main_output_loss: 0.8345 - val_aux_output_loss: 1.8882\n",
      "Epoch 183/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9662 - main_output_loss: 0.8638 - aux_output_loss: 1.8880 - val_loss: 0.9379 - val_main_output_loss: 0.8328 - val_aux_output_loss: 1.8846\n",
      "Epoch 184/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9643 - main_output_loss: 0.8620 - aux_output_loss: 1.8843 - val_loss: 0.9361 - val_main_output_loss: 0.8311 - val_aux_output_loss: 1.8810\n",
      "Epoch 185/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9624 - main_output_loss: 0.8603 - aux_output_loss: 1.8806 - val_loss: 0.9342 - val_main_output_loss: 0.8294 - val_aux_output_loss: 1.8773\n",
      "Epoch 186/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9605 - main_output_loss: 0.8586 - aux_output_loss: 1.8769 - val_loss: 0.9323 - val_main_output_loss: 0.8277 - val_aux_output_loss: 1.8738\n",
      "Epoch 187/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9586 - main_output_loss: 0.8569 - aux_output_loss: 1.8733 - val_loss: 0.9305 - val_main_output_loss: 0.8261 - val_aux_output_loss: 1.8702\n",
      "Epoch 188/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9567 - main_output_loss: 0.8553 - aux_output_loss: 1.8697 - val_loss: 0.9286 - val_main_output_loss: 0.8244 - val_aux_output_loss: 1.8667\n",
      "Epoch 189/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9549 - main_output_loss: 0.8536 - aux_output_loss: 1.8661 - val_loss: 0.9268 - val_main_output_loss: 0.8228 - val_aux_output_loss: 1.8632\n",
      "Epoch 190/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9530 - main_output_loss: 0.8520 - aux_output_loss: 1.8625 - val_loss: 0.9250 - val_main_output_loss: 0.8212 - val_aux_output_loss: 1.8597\n",
      "Epoch 191/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9512 - main_output_loss: 0.8504 - aux_output_loss: 1.8590 - val_loss: 0.9233 - val_main_output_loss: 0.8196 - val_aux_output_loss: 1.8563\n",
      "Epoch 192/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9494 - main_output_loss: 0.8487 - aux_output_loss: 1.8556 - val_loss: 0.9215 - val_main_output_loss: 0.8180 - val_aux_output_loss: 1.8529\n",
      "Epoch 193/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9476 - main_output_loss: 0.8472 - aux_output_loss: 1.8520 - val_loss: 0.9197 - val_main_output_loss: 0.8164 - val_aux_output_loss: 1.8495\n",
      "Epoch 194/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9459 - main_output_loss: 0.8456 - aux_output_loss: 1.8486 - val_loss: 0.9180 - val_main_output_loss: 0.8149 - val_aux_output_loss: 1.8461\n",
      "Epoch 195/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9441 - main_output_loss: 0.8440 - aux_output_loss: 1.8452 - val_loss: 0.9163 - val_main_output_loss: 0.8133 - val_aux_output_loss: 1.8428\n",
      "Epoch 196/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9424 - main_output_loss: 0.8425 - aux_output_loss: 1.8418 - val_loss: 0.9146 - val_main_output_loss: 0.8118 - val_aux_output_loss: 1.8395\n",
      "Epoch 197/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9407 - main_output_loss: 0.8409 - aux_output_loss: 1.8385 - val_loss: 0.9129 - val_main_output_loss: 0.8103 - val_aux_output_loss: 1.8362\n",
      "Epoch 198/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9390 - main_output_loss: 0.8394 - aux_output_loss: 1.8352 - val_loss: 0.9112 - val_main_output_loss: 0.8088 - val_aux_output_loss: 1.8329\n",
      "Epoch 199/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9373 - main_output_loss: 0.8379 - aux_output_loss: 1.8319 - val_loss: 0.9095 - val_main_output_loss: 0.8073 - val_aux_output_loss: 1.8297\n",
      "Epoch 200/200\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9356 - main_output_loss: 0.8364 - aux_output_loss: 1.8285 - val_loss: 0.9079 - val_main_output_loss: 0.8058 - val_aux_output_loss: 1.8265\n"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\") # dont need to use , save_best_only=True because restore_best_weights=True \n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=200,\n",
    "                    validation_data=([X_valid_A, X_valid_B], [y_valid, y_valid]),\n",
    "                    callbacks=[checkpoint_cb, early_stopping_cb, tensorboard_cb])\n",
    "\n",
    "# run on anaconda prompt: tensorboard --logdir=C:\\Users\\taoufik.elkhiraoui\\PycharmProjects\\tf_handson\\my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams fine tuning: wrappe keras model into a sciktlearn model, and use gridsearch as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_new = X_test[:2, :]\n",
    "y_pred = keras_reg.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0,1,2,3],\n",
    "    \"n_neurons\" : np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=2, cv=3) # n_inter: number of parameters samples to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rnd_search_cv.fit(X_train, y_train, epochs=100, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = rnd_search_cv.estimator.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.3055 - val_loss: 1.1383\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7167 - val_loss: 1.0005\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5911 - val_loss: 0.5755\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5507 - val_loss: 0.5774\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 937us/step - loss: 0.5257 - val_loss: 0.8025\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5077 - val_loss: 0.5058\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 972us/step - loss: 0.4948 - val_loss: 0.4988\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4828 - val_loss: 0.7007\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4768\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4717 - val_loss: 0.5031\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4592 - val_loss: 0.4742\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 964us/step - loss: 0.4528 - val_loss: 0.4769\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.4477 - val_loss: 0.4736\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.4425 - val_loss: 0.5824\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4397 - val_loss: 0.4657\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.4441 - val_loss: 0.5402\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4293 - val_loss: 0.4444\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4250 - val_loss: 0.4370\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4211 - val_loss: 0.4305\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4174 - val_loss: 0.4540\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4135 - val_loss: 0.4207\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4120 - val_loss: 0.4515\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4072 - val_loss: 0.4150\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4053 - val_loss: 0.4380\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4110\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 909us/step - loss: 0.3984 - val_loss: 0.4506\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3959 - val_loss: 0.4311\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3932 - val_loss: 0.4494\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3917 - val_loss: 0.3971\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 987us/step - loss: 0.3902 - val_loss: 0.4232\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.4220\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.3944\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4341\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3817 - val_loss: 0.4099\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.3913\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.4292\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3770 - val_loss: 0.3914\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3761 - val_loss: 0.3989\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3740 - val_loss: 0.3916\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3734 - val_loss: 0.4057\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3721 - val_loss: 0.3965\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3716 - val_loss: 0.4167\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3703 - val_loss: 0.3843\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.3695 - val_loss: 0.4062\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3685 - val_loss: 0.3894\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.3679 - val_loss: 0.4118\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.3666 - val_loss: 0.3805\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3665 - val_loss: 0.4231\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3661 - val_loss: 0.3767\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3647 - val_loss: 0.3927\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3644 - val_loss: 0.3875\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3638 - val_loss: 0.3972\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3631 - val_loss: 0.3845\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3621 - val_loss: 0.3830\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3617 - val_loss: 0.3943\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 887us/step - loss: 0.3613 - val_loss: 0.3916\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3606 - val_loss: 0.3985\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3600 - val_loss: 0.3803\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3597 - val_loss: 0.3909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2263c5bb610>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_reg.fit(X_train, y_train, epochs=100, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 698us/step - loss: 0.3686\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.7784914, 3.0260742], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:2, :]\n",
    "y_pred = keras_reg.predict(X_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0,1,2,3],\n",
    "    \"n_neurons\" : np.arange(1, 100),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=2, cv=3) # n_inter: number of parameters samples to try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.0512 - val_loss: 0.5588\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5353 - val_loss: 1.8379\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5097 - val_loss: 4.0797\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5046 - val_loss: 6.3689\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5006 - val_loss: 7.8913\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4989 - val_loss: 9.1181\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4970 - val_loss: 10.0871\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 11.0097\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4992 - val_loss: 10.8695\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4968 - val_loss: 11.6776\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4995 - val_loss: 11.5149\n",
      "121/121 [==============================] - 0s 703us/step - loss: 2.3294\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.1299 - val_loss: 135.7665\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 87.2730 - val_loss: 4783.0005\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5427.2119 - val_loss: 149826.5000\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 155623.8750 - val_loss: 4552549.5000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 235966.1250 - val_loss: 138754832.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 30681732.0000 - val_loss: 4280587776.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4635628544.0000 - val_loss: 128037249024.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9236185088.0000 - val_loss: 5624388648960.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1411544252416.0000 - val_loss: 180620252676096.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6602843750400.0000 - val_loss: 5544933238767616.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 592701326098432.0000 - val_loss: 169128991708413952.0000\n",
      "121/121 [==============================] - 0s 653us/step - loss: 360925529899008.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8380 - val_loss: 116.4796\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 89.8762 - val_loss: 3579.8362\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 218.2652 - val_loss: 120625.9609\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 108148.2812 - val_loss: 3983601.5000\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 150187.3906 - val_loss: 177625568.0000\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 42316148.0000 - val_loss: 6166318592.0000\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5240697344.0000 - val_loss: 206482620416.0000\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 47353937920.0000 - val_loss: 7097254674432.0000\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 816018030592.0000 - val_loss: 348851772850176.0000\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 210896097902592.0000 - val_loss: 11501535871631360.0000\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6017928860270592.0000 - val_loss: 380321415645102080.0000\n",
      "121/121 [==============================] - 0s 661us/step - loss: 1392006551044096.0000\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 3ms/step - loss: 3.1815 - val_loss: 2.5334\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3530 - val_loss: 2.3644\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9436 - val_loss: 2.1822\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8233 - val_loss: 1.9705\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7680 - val_loss: 1.7642\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7352 - val_loss: 1.6003\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7116 - val_loss: 1.4779\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6929 - val_loss: 1.3475\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6767 - val_loss: 1.2439\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6617 - val_loss: 1.1314\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6484 - val_loss: 1.0526\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6355 - val_loss: 0.9820\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6234 - val_loss: 0.9123\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6118 - val_loss: 0.8513\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6009 - val_loss: 0.7899\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5907 - val_loss: 0.7443\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5809 - val_loss: 0.7024\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5716 - val_loss: 0.6636\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5628 - val_loss: 0.6307\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5545 - val_loss: 0.6057\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5465 - val_loss: 0.5832\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - val_loss: 0.5639\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5316 - val_loss: 0.5473\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5247 - val_loss: 0.5379\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5182 - val_loss: 0.5296\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5119 - val_loss: 0.5240\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5059 - val_loss: 0.5215\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5003 - val_loss: 0.5220\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4950 - val_loss: 0.5250\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4899 - val_loss: 0.5300\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4850 - val_loss: 0.5369\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4806 - val_loss: 0.5460\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4760 - val_loss: 0.5541\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4720 - val_loss: 0.5637\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.5738\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4644 - val_loss: 0.5824\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4608 - val_loss: 0.5919\n",
      "121/121 [==============================] - 0s 736us/step - loss: 0.4794\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.7065 - val_loss: 2.8216\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9221 - val_loss: 2.0632\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2889 - val_loss: 1.4910\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9747 - val_loss: 1.1387\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - ETA: 0s - loss: 0.844 - 0s 1ms/step - loss: 0.8241 - val_loss: 0.9451\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7511 - val_loss: 0.8365\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7115 - val_loss: 0.7702\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6860 - val_loss: 0.7286\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6673 - val_loss: 0.7014\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6521 - val_loss: 0.6804\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6391 - val_loss: 0.6672\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6276 - val_loss: 0.6541\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6171 - val_loss: 0.6442\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6075 - val_loss: 0.6316\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6225\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5899 - val_loss: 0.6116\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5820 - val_loss: 0.6026\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - val_loss: 0.5966\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5671 - val_loss: 0.5910\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5600 - val_loss: 0.5829\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5532 - val_loss: 0.5760\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5468 - val_loss: 0.5709\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5407 - val_loss: 0.5669\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5348 - val_loss: 0.5611\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5292 - val_loss: 0.5575\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5237 - val_loss: 0.5511\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5184 - val_loss: 0.5485\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5133 - val_loss: 0.5423\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5084 - val_loss: 0.5398\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5038 - val_loss: 0.5340\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4993 - val_loss: 0.5308\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4950 - val_loss: 0.5260\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4907 - val_loss: 0.5260\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4867 - val_loss: 0.5170\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4826 - val_loss: 0.5179\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4790 - val_loss: 0.5143\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4753 - val_loss: 0.5067\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4720 - val_loss: 0.5078\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4686 - val_loss: 0.5018\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4653 - val_loss: 0.5031\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4623 - val_loss: 0.4993\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4593 - val_loss: 0.4938\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4565 - val_loss: 0.4911\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4538 - val_loss: 0.4879\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4512 - val_loss: 0.4879\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4485 - val_loss: 0.4841\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4461 - val_loss: 0.4800\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4438 - val_loss: 0.4834\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4414 - val_loss: 0.4773\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4394 - val_loss: 0.4751\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4373 - val_loss: 0.4783\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4353 - val_loss: 0.4718\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4334 - val_loss: 0.4761\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4315 - val_loss: 0.4725\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4296 - val_loss: 0.4670\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4279 - val_loss: 0.4690\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4261 - val_loss: 0.4646\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4244 - val_loss: 0.4607\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4228 - val_loss: 0.4663\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4213 - val_loss: 0.4675\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4199 - val_loss: 0.4617\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.4618\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4168 - val_loss: 0.4616\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4154 - val_loss: 0.4598\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4140 - val_loss: 0.4590\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4127 - val_loss: 0.4549\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4114 - val_loss: 0.4542\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.4573\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4090 - val_loss: 0.4538\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4077 - val_loss: 0.4496\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4065 - val_loss: 0.4486\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4054 - val_loss: 0.4478\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4042 - val_loss: 0.4462\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4033 - val_loss: 0.4434\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4021 - val_loss: 0.4434\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4011 - val_loss: 0.4407\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4002 - val_loss: 0.4433\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3992 - val_loss: 0.4410\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3977 - val_loss: 0.4479\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3973 - val_loss: 0.4401\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3962 - val_loss: 0.4355\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3954 - val_loss: 0.4367\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3946 - val_loss: 0.4363\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3937 - val_loss: 0.4340\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3928 - val_loss: 0.4356\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.4353\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3912 - val_loss: 0.4330\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.4354\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3896 - val_loss: 0.4345\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4294\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.4309\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.4301\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.4302\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3861 - val_loss: 0.4304\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.4258\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.4276\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4264\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3834 - val_loss: 0.4263\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.4268\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3821 - val_loss: 0.4229\n",
      "121/121 [==============================] - 0s 818us/step - loss: 0.3969\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3.1175 - val_loss: 3.5541\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5231 - val_loss: 1.9752\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0207 - val_loss: 1.0656\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8451 - val_loss: 0.8743\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7888 - val_loss: 0.8119\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7580 - val_loss: 0.7775\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7363 - val_loss: 0.7536\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7185 - val_loss: 0.7352\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7030 - val_loss: 0.7203\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6886 - val_loss: 0.7091\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6750 - val_loss: 0.6936\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6624 - val_loss: 0.6794\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6504 - val_loss: 0.6673\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6390 - val_loss: 0.6571\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6280 - val_loss: 0.6448\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6178 - val_loss: 0.6352\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6077 - val_loss: 0.6239\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.6177\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5893 - val_loss: 0.6074\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5807 - val_loss: 0.6000\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5720 - val_loss: 0.5905\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5643 - val_loss: 0.5811\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5567 - val_loss: 0.5763\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5493 - val_loss: 0.5684\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5421 - val_loss: 0.5593\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5353 - val_loss: 0.5516\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5496\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5227 - val_loss: 0.5399\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5169 - val_loss: 0.5397\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5110 - val_loss: 0.5276\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5057 - val_loss: 0.5238\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5005 - val_loss: 0.5202\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4953 - val_loss: 0.5157\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4905 - val_loss: 0.5101\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4857 - val_loss: 0.5036\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4815 - val_loss: 0.4991\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4969\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4731 - val_loss: 0.4897\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4693 - val_loss: 0.4901\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4656 - val_loss: 0.4882\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4619 - val_loss: 0.4803\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4586 - val_loss: 0.4782\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4550 - val_loss: 0.4783\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4520 - val_loss: 0.4753\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4489 - val_loss: 0.4680\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4657\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4611\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4404 - val_loss: 0.4598\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4377 - val_loss: 0.4573\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4353 - val_loss: 0.4578\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4327 - val_loss: 0.4517\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4305 - val_loss: 0.4515\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4281 - val_loss: 0.4473\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4262 - val_loss: 0.4482\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4241 - val_loss: 0.4463\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4220 - val_loss: 0.4433\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4202 - val_loss: 0.4433\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4183 - val_loss: 0.4403\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4167 - val_loss: 0.4406\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4149 - val_loss: 0.4411\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4132 - val_loss: 0.4404\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4117 - val_loss: 0.4360\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4102 - val_loss: 0.4346\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4088 - val_loss: 0.4337\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4073 - val_loss: 0.4312\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4060 - val_loss: 0.4301\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4047 - val_loss: 0.4286\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4035 - val_loss: 0.4292\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4022 - val_loss: 0.4266\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4010 - val_loss: 0.4239\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4000 - val_loss: 0.4236\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3989 - val_loss: 0.4252\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.4203\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3968 - val_loss: 0.4204\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3958 - val_loss: 0.4203\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3948 - val_loss: 0.4210\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3938 - val_loss: 0.4164\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3931 - val_loss: 0.4158\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3921 - val_loss: 0.4167\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3913 - val_loss: 0.4154\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3905 - val_loss: 0.4158\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3897 - val_loss: 0.4145\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3889 - val_loss: 0.4112\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3882 - val_loss: 0.4119\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3874 - val_loss: 0.4125\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.4115\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3860 - val_loss: 0.4100\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3853 - val_loss: 0.4115\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.4077\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3840 - val_loss: 0.4074\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3832 - val_loss: 0.4105\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.4036\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.4064\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3816 - val_loss: 0.4041\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3810 - val_loss: 0.4064\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3804 - val_loss: 0.4053\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3798 - val_loss: 0.4042\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3793 - val_loss: 0.4041\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3788 - val_loss: 0.4011\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.3783 - val_loss: 0.4018\n",
      "121/121 [==============================] - 0s 694us/step - loss: 0.3896\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002263E871040>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-e41f2e018dca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m rnd_search_cv.fit(X_train, y_train, epochs=100, \n\u001b[0m\u001b[0;32m      2\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                   callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    759\u001b[0m             \u001b[1;31m# we clone again after setting params in case some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[0m\u001b[0;32m    762\u001b[0m                 **self.best_params_))\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mparam2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams_set\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparam1\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparam2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0m\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                                (estimator, name))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002263E871040>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.fit(X_train, y_train, epochs=100, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0004087057440660127, 'n_hidden': 2, 'n_neurons': 45}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4219512343406677"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.estimator.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x2263c2e8d90>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
